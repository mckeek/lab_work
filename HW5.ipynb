{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT ANALYSIS \n",
    "# BASED ON MILLER (2015) and RASCHKA (2015)\n",
    "\n",
    "\n",
    "\n",
    "# import packages for text processing and multivariate analysis\n",
    "import re  # regular expressions\n",
    "import nltk  # draw on the Python natural language toolkit\n",
    "import pandas as pd  # DataFrame structure and operations\n",
    "import numpy as np  # arrays and numerical processing\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt  # 2D plotting\n",
    "import collections, re\n",
    "\n",
    "# terms-by-documents matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# alternative distance metrics for multidimensional scaling\n",
    "from sklearn.metrics import euclidean_distances \n",
    "from sklearn.metrics.pairwise import linear_kernel as cosine_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances as manhattan_distances\n",
    "\n",
    "from sklearn import manifold  # multidimensional scaling\n",
    "from sklearn.cluster import KMeans  # cluster analysis by partitioning\n",
    "from sklearn.decomposition import PCA  # principal component analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elinor', 2460), ('could', 2252), ('Mrs', 2104), ('would', 2028), ('Marianne', 1952), ('said', 1548), ('every', 1436), ('one', 1160), ('much', 1132), ('must', 1112), ('But', 1096), ('She', 976), ('The', 948), ('time', 940), ('know', 900), ('Dashwood', 896), ('might', 860), ('sister', 852), ('Edward', 836), ('Miss', 828), ('think', 816), ('Jennings', 812), ('though', 808), ('mother', 800), ('He', 792), ('It', 740), ('thing', 736), ('never', 728), ('Mr', 712), ('soon', 708), ('Willoughby', 700), ('without', 684), ('see', 684), ('well', 668), ('ever', 668), ('may', 668), ('nothing', 652), ('Colonel', 648), ('first', 640), ('say', 632), ('Lucy', 624), ('little', 616), ('great', 588), ('house', 584), ('John', 584), ('however', 572), ('two', 568), ('make', 556), ('day', 556), ('made', 548)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    " \n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    " \n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out stop words\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttokens = [w for w in tokens if not w in stop_words]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "\t# load doc\n",
    "\tdoc = load_doc(filename)\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# update counts\n",
    "\tvocab.update(tokens)\n",
    "    \n",
    "# load the document\n",
    "filename = '/Users/kenmckee/Desktop/Austen_Sense.txt'\n",
    "text = load_doc(filename)\n",
    "tokens = clean_doc(text)\n",
    "#print(tokens)\n",
    "vocab.update(tokens)\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
