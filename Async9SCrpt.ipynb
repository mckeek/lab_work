{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "line = '1.1.1.1 - - [21/Feb/2014:06:35:45 +0100] \"GET /robots.txt HTTP/1.1\" 200 112 \"-\" \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Celebrate #NationalPetDay with our puppy playlist: https://t.co/eBHHFPW0z7 https://t.co/uix5AY2FFQ<a href=\"http://msande.stanford.edu\"> Management Science and Engineering </a><p\n",
    "\n",
    "      Address: Terman 311, Stanford CA 94305<br>\n",
    "\n",
    "      Email: ashishg@cs.stanford.edu<br>\n",
    "\n",
    "      Phone: (650)814-9999 [Cell], Fax: (650)723-9999<br>\n",
    "\n",
    "      Admin asst: Roz Morf, Terman 405, 650-723-9999, rozm@stanford.edu</p>\n",
    "\n",
    "The U.S.A. olympic teams have east-west training centers with up-to-date equipment.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celebrate #NationalPetDay with our puppy playlist: https://t.co/eBHHFPW0z7 https://t.co/uix5AY2FFQ<a href=\"http://msande.stanford.edu\"> Management Science and Engineering </a><p\n",
      "\n",
      "      Address: Terman 311, Stanford CA 94305<br>\n",
      "\n",
      "      Email: ashishg@cs.stanford.edu<br>\n",
      "\n",
      "      Phone: (650)814-9999 [Cell], Fax: (650)723-9999<br>\n",
      "\n",
      "      Admin asst: Roz Morf, Terman 405, 650-723-9999, rozm@stanford.edu</p>\n",
      "\n",
      "The U.S.A. olympic teams have east-west training centers with up-to-date equipment.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://t.co/eBHHFPW0z7', 'https://t.co/uix5AY2FFQ<a', 'http://msande.stanford.edu\">']\n"
     ]
    }
   ],
   "source": [
    "#First we extract the date by looking for the string inside of square brackets. To do this, we write a pattern that finds the left square bracket followed by any number of characters that are not a right square bracket and then the right square bracket. A set of parentheses captures the string inside the square brackets.\n",
    "urls = re.findall('https?://\\S+', text)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['650)814-9999', '650)723-9999', '650-723-9999']\n"
     ]
    }
   ],
   "source": [
    "#First we extract the date by looking for the string inside of square brackets. To do this, we write a pattern that finds the left square bracket followed by any number of characters that are not a right square bracket and then the right square bracket. A set of parentheses captures the string inside the square brackets.\n",
    "ptns = re.findall( '[1-9]\\d{1,2}.\\d{2,3}.\\d{2,3}.\\d{0,2}',text)\n",
    "print(ptns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA ', 'U.S.A. ']\n"
     ]
    }
   ],
   "source": [
    "#First we extract the date by looking for the string inside of square brackets. To do this, we write a pattern that finds the left square bracket followed by any number of characters that are not a right square bracket and then the right square bracket. A set of parentheses captures the string inside the square brackets.\n",
    "acro = re.findall( '[A-Z]\\.?[A-Z]\\.?[A-Z]?\\.?\\s',text)\n",
    "print(acro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['814-9999', '723-9999', '650-723-9999', 'east-west', 'up-to-date']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['east-west', 'up-to-date']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we extract the date by looking for the string inside of square brackets. To do this, we write a pattern that finds the left square bracket followed by any number of characters that are not a right square bracket and then the right square bracket. A set of parentheses captures the string inside the square brackets.\n",
    "hyph = re.findall(r'\\w+(?:-\\w+)+',text)\n",
    "print(hyph)\n",
    "\n",
    "re.findall(r'[a-z]+(?:-[a-z]+)+',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GET /robots.txt HTTP/1.1',\n",
       " '-',\n",
       " 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#['21/Feb/2014:06:35:45 +0100']\n",
    "datestring = resultlist[0] \n",
    "#datestring \n",
    "'21/Feb/2014:06:35:45 +0100'\n",
    "#Next, suppose we want to find what server contents are being requested by the GET requests. We can use a similar regular expression to find strings inside the double quotes, where the content of the first set of double quotes represents the request to the server. (Not all of these are GET requests, but they all are formatted with double quotes in this log.)\n",
    "pquotes = re.compile('\\\"([^\\\"]+)\\\"')\n",
    "quotecontents = pquotes.findall(line)\n",
    "quotecontents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GET /robots.txt HTTP/1.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The request string is the first of these.\n",
    "requeststring = quotecontents[0] \n",
    "requeststring\n",
    "#'GET /robots.txt HTTP/1.1'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/robots.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we get the actual server content request by selecting the part after the GET and before the HTTP version information.\n",
    "prequest = re.compile('GET ([\\w/.]+) HTTP') \n",
    "request = prequest.findall(requeststring)\n",
    "request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['/robots.txt']\n",
    "#Now some lines don’t have GET requests.\n",
    "line2 = '7.7.7.7 - - [21/Feb/2014:08:51:34 +0100] \"-\" 400 0 \"- \" \"-\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '- ', '-']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#['GET /robots.txt HTTP/1.1', '-', 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)']\n",
    "\n",
    "#In this case, when we match the GET part, we get an empty string in return because no matches occurred.\n",
    "quotecontents = pquotes.findall(line2) \n",
    "quotecontents\n",
    "#['-', '-', '-']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requeststring = quotecontents[0]\n",
    "request = prequest.findall(requeststring) \n",
    "request\n",
    "#[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 2, 21, 6, 35, 45, tzinfo=datetime.timezone(datetime.timedelta(0, 3600)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As one sidebar, note that we can convert the datestring to a Python datetime object if we want, using strptime.\n",
    "from datetime import datetime\n",
    "tt = datetime.strptime(datestring, \"%d/%b/%Y:%H:%M:%S %z\")\n",
    "tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('21/Feb/2014:06:35:45 +0100', 'GET /robots.txt HTTP/1.1')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datetime.datetime(2014, 2, 21, 6, 35, 45, tzinfo=datetime.timezone(datetime.timedelta(0, 3600)))\n",
    "#As a second sidebar, let’s look at an additional regular expression example. Suppose we want to extract more than one subtext pattern from a text at one time. We can try that with our server log line by making a pattern that looks for the date and the first quoted string at one time.\n",
    "pboth = re.compile('\\[([^\\]]+)\\][^\"]+\\\"([^\\\"]+)\\\"')\n",
    "result = pboth.findall(line)\n",
    "result\n",
    "#[('21/Feb/2014:06:35:45 +0100', 'GET /robots.txt HTTP/1.1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was a really good book.\n",
      "compound: 0.4927, neg: 0.0, neu: 0.556, pos: 0.444, \n",
      "This movie was so bad.\n",
      "compound: -0.6696, neg: 0.529, neu: 0.471, pos: 0.0, \n",
      "I like to hate Michael Bay films, but I couldn't fault this one\n",
      "compound: 0.3153, neg: 0.157, neu: 0.534, pos: 0.309, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sentences = ['This was a really good book.', 'This movie was so bad.',\"I like to hate Michael Bay films, but I couldn't fault this one\"]\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "\tprint(sentence)\n",
    "\tss = sid.polarity_scores(sentence)\n",
    "\tfor k in sorted(ss):\n",
    "\t\tprint('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
