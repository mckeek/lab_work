{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV = ['-1', '0', '1', '-2', '0']\n",
    "MVb = ['-1', '0', '1', '-1', '0']\n",
    "NLTK = ['-2', '1', '0', '0', '0']\n",
    "ss = ['-1', '0', '0', '0', '0']\n",
    "rater1 = ['-1', '0', '-1', '-1', '0']\n",
    "rater2 = ['-1', '1', '-1', '-1', '0']\n",
    "rater3 = ['0', '1', '-1', '-2', '-1']\n",
    "rater4 = ['-1', '2', '-1', '-2', '1']\n",
    "rater5 = ['0', '0', '-1', '-2', '1']\n",
    "\n",
    "NLTKb = ['-1', '1', '0', '0', '0']\n",
    "ssb = ['-1', '0', '0', '0', '0']\n",
    "rater1b = ['-1', '0', '-1', '-1', '0']\n",
    "rater2b = ['-1', '1', '-1', '-1', '0']\n",
    "rater3b = ['0', '1', '-1', '-1', '-1']\n",
    "rater4b = ['-1', '1', '-1', '-1', '1']\n",
    "rater5b = ['0', '0', '-1', '1', '1']\n",
    "#cohen_kappa_score(rater1, rater2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "confusion_matrix() got multiple values for argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0f95dfe2cf25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrater1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrater2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrater3b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: confusion_matrix() got multiple values for argument 'labels'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(rater1b, rater2b, labels=[\"-1\", \"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1&2\n",
      "0.6428571428571428\n",
      "1&3\n",
      "-0.17647058823529416\n",
      "1&4\n",
      "0.21052631578947367\n",
      "1&5\n",
      "0.16666666666666674\n",
      "2&3\n",
      "0.11764705882352955\n",
      "2&4\n",
      "0.16666666666666674\n",
      "2&5\n",
      "-0.11111111111111116\n",
      "3&4\n",
      "0.21052631578947367\n",
      "3&5\n",
      "0.21052631578947378\n",
      "4&5\n",
      "0.2857142857142859\n",
      "k1\n",
      "-0.05263157894736836\n",
      "k2\n",
      "0.2857142857142857\n",
      "k3\n",
      "0.0\n",
      "k4\n",
      "-0.0869565217391306\n",
      "k5\n",
      "-0.47058823529411753\n",
      "s1\n",
      "0.2857142857142857\n",
      "s2\n",
      "0.16666666666666674\n",
      "s3\n",
      "-0.38888888888888884\n",
      "s4\n",
      "0.09090909090909094\n",
      "s5\n",
      "-0.25\n",
      "k1\n",
      "-0.05263157894736836\n",
      "k2\n",
      "0.2857142857142857\n",
      "k3\n",
      "0.04761904761904767\n",
      "k4\n",
      "0.13043478260869557\n",
      "k5\n",
      "-0.47058823529411753\n",
      "s1\n",
      "0.2857142857142857\n",
      "s2\n",
      "0.16666666666666674\n",
      "s3\n",
      "-0.3157894736842106\n",
      "s4\n",
      "0.1304347826086958\n",
      "s5\n",
      "-0.25\n",
      "\n",
      "1&2\n",
      "0.6428571428571428\n",
      "1&3\n",
      "-0.0714285714285714\n",
      "1&4\n",
      "0.375\n",
      "1&5\n",
      "0.16666666666666674\n",
      "2&3\n",
      "0.2857142857142857\n",
      "2&4\n",
      "0.6428571428571428\n",
      "2&5\n",
      "-0.11111111111111116\n",
      "3&4\n",
      "0.2857142857142857\n",
      "3&5\n",
      "0.16666666666666663\n",
      "4&5\n",
      "0.16666666666666674\n",
      "ss$nltk\n",
      "0.23076923076923084\n",
      "ssb$nltkb\n",
      "0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "print(\"1&2\")\n",
    "print(cohen_kappa_score(rater1, rater2)) \n",
    "print(\"1&3\")\n",
    "print(cohen_kappa_score(rater1, rater3))\n",
    "print(\"1&4\")\n",
    "print(cohen_kappa_score(rater1, rater4))\n",
    "print(\"1&5\")\n",
    "print(cohen_kappa_score(rater1, rater5))\n",
    "print(\"2&3\")\n",
    "print(cohen_kappa_score(rater2, rater3))\n",
    "print(\"2&4\")\n",
    "print(cohen_kappa_score(rater2, rater4))\n",
    "print(\"2&5\")\n",
    "print(cohen_kappa_score(rater2, rater5))\n",
    "print(\"3&4\")\n",
    "print(cohen_kappa_score(rater3, rater4))\n",
    "print(\"3&5\")\n",
    "print(cohen_kappa_score(rater3, rater5))\n",
    "print(\"4&5\")\n",
    "print(cohen_kappa_score(rater4, rater5))\n",
    "\n",
    "print(\"k1\")\n",
    "print(cohen_kappa_score(NLTK, rater1))\n",
    "print(\"k2\")\n",
    "print(cohen_kappa_score(NLTK, rater2))\n",
    "print(\"k3\")\n",
    "print(cohen_kappa_score(NLTK, rater3))\n",
    "print(\"k4\")\n",
    "print(cohen_kappa_score(NLTK, rater4))\n",
    "print(\"k5\")\n",
    "print(cohen_kappa_score(NLTK, rater5))\n",
    "\n",
    "print(\"s1\")\n",
    "print(cohen_kappa_score(ss, rater1b))\n",
    "print(\"s2\")\n",
    "print(cohen_kappa_score(ss, rater2b))\n",
    "print(\"s3\")\n",
    "print(cohen_kappa_score(ss, rater3b))\n",
    "print(\"s4\")\n",
    "print(cohen_kappa_score(ss, rater4b))\n",
    "print(\"s5\")\n",
    "print(cohen_kappa_score(ss, rater5b))\n",
    "\n",
    "print(\"k1\")\n",
    "print(cohen_kappa_score(NLTK, rater1b))\n",
    "print(\"k2\")\n",
    "print(cohen_kappa_score(NLTK, rater2b))\n",
    "print(\"k3\")\n",
    "print(cohen_kappa_score(NLTK, rater3b))\n",
    "print(\"k4\")\n",
    "print(cohen_kappa_score(NLTK, rater4b))\n",
    "print(\"k5\")\n",
    "print(cohen_kappa_score(NLTK, rater5b))\n",
    "\n",
    "print(\"s1\")\n",
    "print(cohen_kappa_score(ss, rater1))\n",
    "print(\"s2\")\n",
    "print(cohen_kappa_score(ss, rater2))\n",
    "print(\"s3\")\n",
    "print(cohen_kappa_score(ss, rater3))\n",
    "print(\"s4\")\n",
    "print(cohen_kappa_score(ss, rater4))\n",
    "print(\"s5\")\n",
    "print(cohen_kappa_score(ss, rater5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"1&2\")\n",
    "print(cohen_kappa_score(rater1b, rater2b)) \n",
    "print(\"1&3\")\n",
    "print(cohen_kappa_score(rater1b, rater3b))\n",
    "print(\"1&4\")\n",
    "print(cohen_kappa_score(rater1b, rater4b))\n",
    "print(\"1&5\")\n",
    "print(cohen_kappa_score(rater1b, rater5b))\n",
    "print(\"2&3\")\n",
    "print(cohen_kappa_score(rater2b, rater3b))\n",
    "print(\"2&4\")\n",
    "print(cohen_kappa_score(rater2b, rater4b))\n",
    "print(\"2&5\")\n",
    "print(cohen_kappa_score(rater2b, rater5b))\n",
    "print(\"3&4\")\n",
    "print(cohen_kappa_score(rater3b, rater4b))\n",
    "print(\"3&5\")\n",
    "print(cohen_kappa_score(rater3b, rater5b))\n",
    "print(\"4&5\")\n",
    "print(cohen_kappa_score(rater4b, rater5b))\n",
    "\n",
    "print(\"ss$nltk\")\n",
    "print(cohen_kappa_score(ss, NLTK))\n",
    "print(\"ssb$nltkb\")\n",
    "print(cohen_kappa_score(ssb, NLTKb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1\n",
      "0.4444444444444444\n",
      "k2\n",
      "0.21052631578947367\n",
      "k3\n",
      "-0.05263157894736836\n",
      "k4\n",
      "0.2857142857142859\n",
      "k5\n",
      "-0.11111111111111116\n",
      "k1\n",
      "0.6666666666666666\n",
      "k2\n",
      "0.375\n",
      "k3\n",
      "-0.25\n",
      "k4\n",
      "0.11764705882352944\n",
      "k5\n",
      "-0.17647058823529416\n",
      "NL/MV\n",
      "-0.17647058823529416\n",
      "ss/MV\n",
      "0.375\n",
      "ssb/mvb\n",
      "0.33333333333333337\n",
      "nlb/mvb\n",
      "0.06249999999999989\n"
     ]
    }
   ],
   "source": [
    "print(\"k1\")\n",
    "print(cohen_kappa_score(MV, rater1))\n",
    "print(\"k2\")\n",
    "print(cohen_kappa_score(MV, rater2))\n",
    "print(\"k3\")\n",
    "print(cohen_kappa_score(MV, rater3))\n",
    "print(\"k4\")\n",
    "print(cohen_kappa_score(MV, rater4))\n",
    "print(\"k5\")\n",
    "print(cohen_kappa_score(MV, rater5))\n",
    "\n",
    "print(\"k1\")\n",
    "print(cohen_kappa_score(MVb, rater1b))\n",
    "print(\"k2\")\n",
    "print(cohen_kappa_score(MVb, rater2b))\n",
    "print(\"k3\")\n",
    "print(cohen_kappa_score(MVb, rater3b))\n",
    "print(\"k4\")\n",
    "print(cohen_kappa_score(MVb, rater4b))\n",
    "print(\"k5\")\n",
    "print(cohen_kappa_score(MVb, rater5b))\n",
    "\n",
    "\n",
    "print(\"NL/MV\")\n",
    "print(cohen_kappa_score(MV, NLTK))\n",
    "print(\"ss/MV\")\n",
    "print(cohen_kappa_score(MV, ss))\n",
    "print(\"ssb/mvb\")\n",
    "print(cohen_kappa_score(MVb, ssb))\n",
    "print(\"nlb/mvb\")\n",
    "print(cohen_kappa_score(MVb, NLTKb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five level \n",
      "kappa 0.1723549068750307\n",
      "fleiss 0.16666666666666652\n",
      " \n",
      "three level \n",
      "kappa 0.2549603174603174\n",
      "fleiss 0.16666666666666652\n",
      "0\t0\t-,1\r\n",
      "0\t1\t0\r\n",
      "0\t2\t-,1\r\n",
      "0\t3\t-,1\r\n",
      "0\t4\t0\r\n",
      "1\t0\t-,1\r\n",
      "1\t1\t1\r\n",
      "1\t2\t-,1\r\n",
      "1\t3\t-,1\r\n",
      "1\t4\t0\r\n",
      "2\t0\t0\r\n",
      "2\t1\t1\r\n",
      "2\t2\t-,1\r\n",
      "2\t3\t-,2\r\n",
      "2\t4\t-,1\r\n",
      "3\t0\t-,1\r\n",
      "3\t1\t2\r\n",
      "3\t2\t-,1\r\n",
      "3\t3\t-,2\r\n",
      "3\t4\t1\r\n",
      "4\t0\t0\r\n",
      "4\t1\t0\r\n",
      "4\t2\t-,1\r\n",
      "4\t3\t1\r\n",
      "4\t4\t1\n",
      "[[0, '0', '-1'], [0, '1', '0'], [0, '2', '-1'], [0, '3', '-1'], [0, '4', '0'], [1, '0', '-1'], [1, '1', '1'], [1, '2', '-1'], [1, '3', '-1'], [1, '4', '0'], [2, '0', '0'], [2, '1', '1'], [2, '2', '-1'], [2, '3', '-2'], [2, '4', '-1'], [3, '0', '-1'], [3, '1', '2'], [3, '2', '-1'], [3, '3', '-2'], [3, '4', '1'], [4, '0', '0'], [4, '1', '0'], [4, '2', '-1'], [4, '3', '1'], [4, '4', '1']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import agreement\n",
    "taskdata=[[0,str(i),str(rater1[i])] \n",
    "          for i in range(0,len(rater1))]+[[1,str(i),str(rater2[i])] \n",
    "          for i in range(0,len(rater2))]+[[2,str(i),str(rater3[i])] \n",
    "          for i in range(0,len(rater3))]+[[3,str(i),str(rater4[i])] \n",
    "          for i in range(0,len(rater4))]+[[4,str(i),str(rater5[i])] \n",
    "          for i in range(0,len(rater5))]\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"five level \")\n",
    "print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "print(\" \")\n",
    "from nltk import agreement\n",
    "taskdatab=[[0,str(i),str(rater1b[i])] \n",
    "          for i in range(0,len(rater1b))]+[[1,str(i),str(rater2b[i])] \n",
    "          for i in range(0,len(rater2b))]+[[2,str(i),str(rater3b[i])] \n",
    "          for i in range(0,len(rater3b))]+[[3,str(i),str(rater4b[i])] \n",
    "          for i in range(0,len(rater4b))]+[[4,str(i),str(rater5b[i])] \n",
    "          for i in range(0,len(rater5b))]\n",
    "\n",
    "ratingtaskb = agreement.AnnotationTask(data=taskdatab)\n",
    "print(\"three level \")\n",
    "print(\"kappa \" +str(ratingtaskb.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "\n",
    "#print(\"alpha \" +str(ratingtask.alpha()))\n",
    "#print(\"scotts \" + str(ratingtask.pi()))\n",
    "\n",
    "print(ratingtask)\n",
    "print(taskdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
